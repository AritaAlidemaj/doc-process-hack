{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Processing with Azure\n",
    "\n",
    "This notebook demonstrates how to upload data to Azure Blob Storage, process the data using Azure Document Intelligence, and retrieve the information from these documents in JSON format. The steps include:\n",
    "\n",
    "1. **Upload Data to Blob Storage**: We will upload documents to Azure Blob Storage for processing.\n",
    "2. **Process Data with Azure Document Intelligence**: Utilize Azure's Document Intelligence capabilities to analyze and extract information from the uploaded documents.\n",
    "3. **Retrieve Information in JSON Format**: Extract and retrieve the processed information in JSON format for further use.\n",
    "\n",
    "## Importance of Document Processing\n",
    "\n",
    "Automating document processing is crucial for improving efficiency and accuracy in handling large volumes of data. By leveraging Azure's cloud services, organizations can streamline their workflows, reduce manual errors, and gain valuable insights from their documents. This approach not only saves time and resources but also enhances data accessibility and decision-making capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1- Upload Data to Blob\n",
    "\n",
    "In this step, we will upload our documents to Azure Blob Storage, which serves as a scalable and secure storage solution for our data. The data used is stored in this repo's *data* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded readme.md to blob storage.\n",
      "Uploaded loanagreements/la_janesmith.pdf to blob storage.\n",
      "Uploaded loanform/lpjohndoe.pdf to blob storage.\n",
      "Uploaded loanform/lp_janesmith.pdf to blob storage.\n",
      "Uploaded paystubs/paystubjanesmith.pdf to blob storage.\n",
      "Uploaded paystubs/paystubjohndoe.pdf to blob storage.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the connection string and data folder from the environment variables\n",
    "connection_string = os.getenv('connection_string')\n",
    "data_folder = os.getenv('data_folder')\n",
    "container_name = os.getenv('container_name')\n",
    "\n",
    "# Ensure the connection string, data folder, and container name are not None\n",
    "if connection_string is None:\n",
    "    raise ValueError(\"The connection string environment variable is not set.\")\n",
    "if data_folder is None:\n",
    "    raise ValueError(\"The data folder environment variable is not set.\")\n",
    "if container_name is None:\n",
    "    raise ValueError(\"The container name environment variable is not set.\")\n",
    "\n",
    "# Ensure the data folder exists\n",
    "if not os.path.isdir(data_folder):\n",
    "    raise FileNotFoundError(f\"The specified data folder does not exist: {data_folder}\")\n",
    "\n",
    "# Create a BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "# Upload files in the data folder and its subdirectories to the blob container\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(root, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            # Create a blob path that maintains the directory structure\n",
    "            blob_path = os.path.relpath(file_path, data_folder).replace(\"\\\\\", \"/\")\n",
    "            blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_path)\n",
    "            with open(file_path, \"rb\") as data:\n",
    "                blob_client.upload_blob(data, overwrite=True)\n",
    "            print(f\"Uploaded {blob_path} to blob storage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Process Data with Azure Document Intelligence\n",
    "\n",
    "In this step, we will use Azure Document Intelligence to analyze and extract information from the uploaded documents. The code demonstrates how to authenticate with Azure, submit a document for analysis, and retrieve the results, including detected languages, lines, words, and paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document: https://stgweaihack.blob.core.windows.net/bankdetail/loanagreements/la_janesmith.pdf?se=2024-09-02T16%3A49%3A12Z&sp=r&sv=2021-08-06&sr=b&sig=XpFmy1V2azh8mmTRzQUBlYy%2BOEafG9Zvw1SHA7O25Ms%3D\n",
      "Failed to process document loanagreements/la_janesmith.pdf: 'BoundingRegion' object has no attribute 'bounding_box'\n",
      "Processing document: https://stgweaihack.blob.core.windows.net/bankdetail/loanform/lp_janesmith.pdf?se=2024-09-02T16%3A49%3A18Z&sp=r&sv=2021-08-06&sr=b&sig=kXquo9ZOsiuhE8SJcXkc3jG5h1%2Bi915KCP/9Ux/Kq0c%3D\n",
      "Failed to process document loanform/lp_janesmith.pdf: 'BoundingRegion' object has no attribute 'bounding_box'\n",
      "Processing document: https://stgweaihack.blob.core.windows.net/bankdetail/loanform/lpjohndoe.pdf?se=2024-09-02T16%3A49%3A22Z&sp=r&sv=2021-08-06&sr=b&sig=jYfSEQSKbQv6IIYrKTyiJh4SLHN983OgxLDCuAvitEU%3D\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 173\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HttpResponseError\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     \u001b[43mprocess_blob_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HttpResponseError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# Examples of how to check an HttpResponseError\u001b[39;00m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;66;03m# Check by error code:\u001b[39;00m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error\u001b[38;5;241m.\u001b[39merror \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[39], line 162\u001b[0m, in \u001b[0;36mprocess_blob_documents\u001b[1;34m()\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing document: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msas_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m     analysis_results \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43msas_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     save_analysis_results(blob_service_client, container_name, blob\u001b[38;5;241m.\u001b[39mname, analysis_results)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[39], line 65\u001b[0m, in \u001b[0;36manalyze_read\u001b[1;34m(blob_url)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Analyze a document from the blob URL\u001b[39;00m\n\u001b[0;32m     59\u001b[0m poller \u001b[38;5;241m=\u001b[39m document_intelligence_client\u001b[38;5;241m.\u001b[39mbegin_analyze_document(\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprebuilt-read\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     61\u001b[0m     AnalyzeDocumentRequest(url_source\u001b[38;5;241m=\u001b[39mblob_url),\n\u001b[0;32m     62\u001b[0m     features\u001b[38;5;241m=\u001b[39m[DocumentAnalysisFeature\u001b[38;5;241m.\u001b[39mLANGUAGES]\n\u001b[0;32m     63\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m result: AnalyzeResult \u001b[38;5;241m=\u001b[39m \u001b[43mpoller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Collect analysis results\u001b[39;00m\n\u001b[0;32m     68\u001b[0m analysis_results \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparagraphs\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[0;32m     72\u001b[0m }\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\azure\\core\\polling\\_poller.py:251\u001b[0m, in \u001b[0;36mLROPoller.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PollingReturnType_co:\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the result of the long running operation, or\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m    the result available after the specified timeout.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m    :raises ~azure.core.exceptions.HttpResponseError: Server problem with the query.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_polling_method\u001b[38;5;241m.\u001b[39mresource()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\azure\\core\\polling\\_poller.py:266\u001b[0m, in \u001b[0;36mLROPoller.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;66;03m# Let's handle possible None in forgiveness here\u001b[39;00m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m# https://github.com/python/mypy/issues/8165\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:1119\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:1139\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1140\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import DocumentAnalysisFeature, AnalyzeResult, AnalyzeDocumentRequest\n",
    "\n",
    "def generate_sas_url(blob_service_client, container_name, blob_name, expiry_hours=1):\n",
    "    \"\"\"\n",
    "    Generate a SAS URL for a blob in Azure Blob Storage.\n",
    "\n",
    "    :param blob_service_client: BlobServiceClient instance\n",
    "    :param container_name: Name of the container\n",
    "    :param blob_name: Name of the blob\n",
    "    :param expiry_hours: Expiry time in hours for the SAS token\n",
    "    :return: SAS URL for the blob\n",
    "    \"\"\"\n",
    "    sas_token = generate_blob_sas(\n",
    "        account_name=blob_service_client.account_name,\n",
    "        container_name=container_name,\n",
    "        blob_name=blob_name,\n",
    "        account_key=blob_service_client.credential.account_key,\n",
    "        permission=BlobSasPermissions(read=True),\n",
    "        expiry=datetime.utcnow() + timedelta(hours=expiry_hours)\n",
    "    )\n",
    "\n",
    "    sas_url = f\"https://{blob_service_client.account_name}.blob.core.windows.net/{container_name}/{blob_name}?{sas_token}\"\n",
    "    return sas_url\n",
    "\n",
    "def get_words(page, line):\n",
    "    result = []\n",
    "    for word in page.words:\n",
    "        if _in_span(word, line.spans):\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "def _in_span(word, spans):\n",
    "    for span in spans:\n",
    "        if word.span.offset >= span.offset and (word.span.offset + word.span.length) <= (span.offset + span.length):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def bounding_region_to_dict(region):\n",
    "    return {\n",
    "        \"page_number\": region.page_number,\n",
    "        \"bounding_box\": [point for point in region.bounding_box]\n",
    "    }\n",
    "\n",
    "def analyze_read(blob_url):\n",
    "    # For how to obtain the endpoint and key, please see PREREQUISITES above.\n",
    "    endpoint = os.environ[\"DOCUMENTINTELLIGENCE_ENDPOINT\"]\n",
    "    key = os.environ[\"DOCUMENTINTELLIGENCE_API_KEY\"]\n",
    "\n",
    "    document_intelligence_client = DocumentIntelligenceClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "\n",
    "    # Analyze a document from the blob URL\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        \"prebuilt-read\",\n",
    "        AnalyzeDocumentRequest(url_source=blob_url),\n",
    "        features=[DocumentAnalysisFeature.LANGUAGES]\n",
    "    )\n",
    "    \n",
    "    result: AnalyzeResult = poller.result()\n",
    "    \n",
    "    # Collect analysis results\n",
    "    analysis_results = {\n",
    "        \"languages\": [],\n",
    "        \"pages\": [],\n",
    "        \"paragraphs\": []\n",
    "    }\n",
    "\n",
    "    # Detect languages.\n",
    "    if result.languages is not None:\n",
    "        for language in result.languages:\n",
    "            analysis_results[\"languages\"].append({\n",
    "                \"locale\": language.locale,\n",
    "                \"confidence\": language.confidence\n",
    "            })\n",
    "    \n",
    "    # Analyze pages.\n",
    "    for page in result.pages:\n",
    "        page_info = {\n",
    "            \"page_number\": page.page_number,\n",
    "            \"width\": page.width,\n",
    "            \"height\": page.height,\n",
    "            \"unit\": page.unit,\n",
    "            \"lines\": []\n",
    "        }\n",
    "\n",
    "        # Analyze lines.\n",
    "        if page.lines:\n",
    "            for line_idx, line in enumerate(page.lines):\n",
    "                words = get_words(page, line)\n",
    "                line_info = {\n",
    "                    \"line_idx\": line_idx,\n",
    "                    \"words\": [{\"content\": word.content, \"confidence\": word.confidence} for word in words],\n",
    "                    \"text\": line.content,\n",
    "                    \"polygon\": line.polygon\n",
    "                }\n",
    "                page_info[\"lines\"].append(line_info)\n",
    "        \n",
    "        analysis_results[\"pages\"].append(page_info)\n",
    "        \n",
    "    # Analyze paragraphs.\n",
    "    if result.paragraphs:\n",
    "        for paragraph in result.paragraphs:\n",
    "            analysis_results[\"paragraphs\"].append({\n",
    "                \"bounding_regions\": [bounding_region_to_dict(region) for region in paragraph.bounding_regions],\n",
    "                \"content\": paragraph.content\n",
    "            })\n",
    "\n",
    "    return analysis_results\n",
    "\n",
    "def save_analysis_results(blob_service_client, container_name, blob_name, analysis_results):\n",
    "    \"\"\"\n",
    "    Save the analysis results to the same blob storage.\n",
    "\n",
    "    :param blob_service_client: BlobServiceClient instance\n",
    "    :param container_name: Name of the container\n",
    "    :param blob_name: Name of the blob\n",
    "    :param analysis_results: Analysis results to save\n",
    "    \"\"\"\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_client = container_client.get_blob_client(blob_name + \".json\")\n",
    "\n",
    "    # Convert analysis results to JSON string\n",
    "    analysis_results_json = json.dumps(analysis_results, indent=2)\n",
    "\n",
    "    # Upload the JSON string to the blob\n",
    "    blob_client.upload_blob(analysis_results_json, overwrite=True)\n",
    "\n",
    "def process_blob_documents():\n",
    "    # Load environment variables from .env file\n",
    "    load_dotenv(find_dotenv())\n",
    "\n",
    "    # Retrieve the connection string and container name from the environment variables\n",
    "    connection_string = os.getenv('connection_string')\n",
    "    container_name = os.getenv('container_name')\n",
    "\n",
    "    # Ensure the connection string is not None\n",
    "    if connection_string is None:\n",
    "        raise ValueError(\"The connection string environment variable is not set.\")\n",
    "\n",
    "    # Create a BlobServiceClient\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "    # List and process documents in the specified container\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_list = container_client.list_blobs()\n",
    "\n",
    "    supported_formats = {\".pdf\", \".jpeg\", \".jpg\", \".png\", \".tiff\", \".bmp\"}\n",
    "\n",
    "    for blob in blob_list:\n",
    "        file_extension = os.path.splitext(blob.name)[1].lower()\n",
    "        \n",
    "        if file_extension in supported_formats:\n",
    "            sas_url = generate_sas_url(blob_service_client, container_name, blob.name)\n",
    "            print(f\"Processing document: {sas_url}\")\n",
    "            try:\n",
    "                analysis_results = analyze_read(sas_url)\n",
    "                save_analysis_results(blob_service_client, container_name, blob.name, analysis_results)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process document {blob.name}: {e}\")\n",
    "        else:\n",
    "            print(f\"Skipping unsupported file format: {blob.name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "    try:\n",
    "        process_blob_documents()\n",
    "    except HttpResponseError as error:\n",
    "        # Examples of how to check an HttpResponseError\n",
    "        # Check by error code:\n",
    "        if error.error is not None:\n",
    "            if error.error.code == \"InvalidImage\":\n",
    "                print(f\"Received an invalid image error: {error.error}\")\n",
    "            if error.error.code == \"InvalidRequest\":\n",
    "                print(f\"Received an invalid request error: {error.error}\")\n",
    "            # Raise the error again after printing it\n",
    "            raise\n",
    "        # If the inner error is None and then it is possible to check the message to get more information:\n",
    "        if \"Invalid request\".casefold() in error.message.casefold():\n",
    "            print(f\"Uh-oh! Seems there was an invalid request: {error}\")\n",
    "        # Raise the error again\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Retrieve Information in JSON Format\n",
    "\n",
    "In this step, we will extract and retrieve the processed information from the documents in JSON format. This will allow us to further analyze and utilize the extracted data for various purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.documentintelligence import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import json\n",
    "\n",
    "\n",
    "# Create a DocumentAnalysisClient\n",
    "document_analysis_client = DocumentAnalysisClient(endpoint=os.getenv(\"DOCUMENTINTELLIGENCE_ENDPOINT\"), credential=AzureKeyCredential(os.getenv(\"DOCUMENTINTELLIGENCE_API_KEY\")))\n",
    "\n",
    "# Function to analyze a document from blob storage\n",
    "def analyze_document(blob_url):\n",
    "    poller = document_analysis_client.begin_analyze_document_from_url(\"prebuilt-document\", blob_url)\n",
    "    result = poller.result()\n",
    "    return result\n",
    "\n",
    "# Retrieve and process documents from blob storage\n",
    "container_client = blob_service_client.get_container_client(os.getenv(\"container_name\"))\n",
    "blob_list = container_client.list_blobs()\n",
    "\n",
    "for blob in blob_list:\n",
    "    blob_url = f\"https://{blob_service_client.account_name}.blob.core.windows.net/{os.getenv(\"container_name\")}/{blob.name}\"\n",
    "    result = analyze_document(blob_url)\n",
    "    \n",
    "    # Convert result to JSON format\n",
    "    result_json = result.to_dict()\n",
    "    print(json.dumps(result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Structure the Retrieved Data (ou por no Blob os jsons?)\n",
    "\n",
    "In this step, we will structure the data retrieved from Azure Document Intelligence. The data will be outputted as a JSON file, and it is our role to process and organize it. Some of the data will be structured into tables, while other data will be formatted as text. This step ensures that the extracted information is organized in a meaningful way for further analysis and usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
